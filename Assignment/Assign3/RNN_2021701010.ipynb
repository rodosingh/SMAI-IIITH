{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y45yhDufI5Uo"
   },
   "source": [
    "# **RNN**\n",
    "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55i8db8uI5U3"
   },
   "source": [
    "IMDB sentiment classification task\n",
    "\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. IMDB provided a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided.\n",
    "\n",
    "You can download the dataset from http://ai.stanford.edu/~amaas/data/sentiment/  or you can directly use \n",
    "\" from keras.datasets import imdb \" to import the dataset.\n",
    "\n",
    "Few points to be noted:\n",
    "Modules like SimpleRNN, LSTM, Activation layers, Dense layers, Dropout can be directly used from keras\n",
    "For preprocessing, you can use required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:22:46.951681Z",
     "iopub.status.busy": "2021-11-27T06:22:46.951400Z",
     "iopub.status.idle": "2021-11-27T06:22:52.408243Z",
     "shell.execute_reply": "2021-11-27T06:22:52.407445Z",
     "shell.execute_reply.started": "2021-11-27T06:22:46.951650Z"
    },
    "id": "SozhvLNkI5U6",
    "outputId": "2f3a96d4-df0b-4302-a067-4a8187225d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "#load the imdb dataset \n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "vocabulary_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:22:58.170749Z",
     "iopub.status.busy": "2021-11-27T06:22:58.170257Z",
     "iopub.status.idle": "2021-11-27T06:22:58.182952Z",
     "shell.execute_reply": "2021-11-27T06:22:58.182147Z",
     "shell.execute_reply.started": "2021-11-27T06:22:58.170709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version: 2.6.0 , GPU: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 06:22:58.173094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-27 06:22:58.173947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-27 06:22:58.174588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-27 06:22:58.175319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-27 06:22:58.176024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-27 06:22:58.176603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# Check if the GPU is in place\n",
    "from keras import backend as k\n",
    "if k.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name == '':\n",
    "        device_name = \"None\"\n",
    "    print('Using TensorFlow version:', tf.__version__, ', GPU:', device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:23:35.116941Z",
     "iopub.status.busy": "2021-11-27T06:23:35.116192Z",
     "iopub.status.idle": "2021-11-27T06:23:35.198954Z",
     "shell.execute_reply": "2021-11-27T06:23:35.198101Z",
     "shell.execute_reply.started": "2021-11-27T06:23:35.116900Z"
    },
    "id": "NrilwfurI5VA",
    "outputId": "6dfcb513-c8c7-416c-f571-5e85e90b6552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review---\n",
      "[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n",
      "---label---\n",
      "0\n",
      "---review with words---\n",
      "['the', 'as', 'there', 'in', 'at', 'by', 'br', 'of', 'sure', 'many', 'br', 'of', 'and', 'no', 'only', 'women', 'was', 'than', \"doesn't\", 'as', 'you', 'never', 'of', 'hat', 'night', 'that', 'with', 'ignored', 'they', 'bad', 'out', 'superman', 'plays', 'of', 'how', 'star', 'so', 'stories', 'film', 'comes', 'defense', 'date', 'of', 'wide', 'they', \"don't\", 'do', 'that', 'had', 'with', 'of', 'hollywood', 'br', 'of', 'my', 'seeing', 'fan', 'this', 'of', 'pop', 'out', 'body', 'shots', 'in', 'having', 'because', 'cause', \"it's\", 'stick', 'passing', 'first', 'were', 'enjoys', 'for', 'from', 'look', 'seven', 'sense', 'from', 'me', 'and', 'die', 'in', 'character', 'as', 'and', 'issues', 'but', 'is', 'you', 'that', \"isn't\", 'one', 'song', 'just', 'is', 'him', 'less', 'are', 'strongly', 'not', 'are', 'you', 'that', 'different', 'just', 'even', 'by', 'this', 'of', 'you', 'there', 'is', 'eight', 'when', 'it', 'part', 'are', \"film's\", 'love', \"film's\", \"80's\", 'was', 'big', 'also', 'light', \"don't\", 'and', 'as', 'it', 'in', 'character', 'looked', 'cinematography', 'so', 'stories', 'is', 'far', 'br', 'man', 'acting']\n",
      "---label---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#the review is stored as a sequence of integers. \n",
    "# These are word IDs that have been pre-assigned to individual words, and the label is an integer\n",
    "\n",
    "print('---review---')\n",
    "print(X_train[2])\n",
    "print('---label---')\n",
    "print(y_train[2])\n",
    "\n",
    "# to get the actual review\n",
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print('---review with words---')\n",
    "print([id2word.get(i, ' ') for i in X_train[2]])\n",
    "print('---label---')\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:23:45.491456Z",
     "iopub.status.busy": "2021-11-27T06:23:45.490919Z",
     "iopub.status.idle": "2021-11-27T06:23:46.980800Z",
     "shell.execute_reply": "2021-11-27T06:23:46.980036Z",
     "shell.execute_reply.started": "2021-11-27T06:23:45.491417Z"
    },
    "id": "h6upWxEWI5VC"
   },
   "outputs": [],
   "source": [
    "#pad sequences (write your code here)\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=132)\n",
    "X_test = pad_sequences(X_test, maxlen=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:43:19.396769Z",
     "iopub.status.busy": "2021-11-27T06:43:19.396048Z",
     "iopub.status.idle": "2021-11-27T06:43:19.557149Z",
     "shell.execute_reply": "2021-11-27T06:43:19.556447Z",
     "shell.execute_reply.started": "2021-11-27T06:43:19.396734Z"
    },
    "id": "-RcCOpeNI5VF"
   },
   "outputs": [],
   "source": [
    "#design a RNN model (write your code)\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN\n",
    "\n",
    "embedding_size=32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=132, mask_zero=True))\n",
    "model.add(SimpleRNN(128,dropout=0.1, recurrent_dropout=0.1,return_sequences=True))\n",
    "model.add(SimpleRNN(64,dropout=0.1, recurrent_dropout=0.1,return_sequences=False))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reason:\n",
    "For `binary classification` (like **sentiment analysis** in our case), the loss function **`binary_crossentropy`** is a defacto standard, and **`Adam`** or adaptive momentum optimizer is suitable for optimization in deep learning models as it can handle **sparse gradients** and does not stop at saddle points as it employs momentum, so it continues further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:43:21.815523Z",
     "iopub.status.busy": "2021-11-27T06:43:21.815073Z",
     "iopub.status.idle": "2021-11-27T06:43:21.831826Z",
     "shell.execute_reply": "2021-11-27T06:43:21.831015Z",
     "shell.execute_reply.started": "2021-11-27T06:43:21.815485Z"
    },
    "id": "InQ2TED3I5VI",
    "outputId": "482c9397-2cb1-46dc-b385-b870e3cfe1a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 132, 32)           160000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 132, 128)          20608     \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 197,185\n",
      "Trainable params: 197,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#train and evaluate your model\n",
    "#choose your loss function and optimizer and mention the reason to choose that particular loss function and optimizer\n",
    "# use accuracy as the evaluation metric\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:43:32.910862Z",
     "iopub.status.busy": "2021-11-27T06:43:32.910312Z",
     "iopub.status.idle": "2021-11-27T06:48:01.980506Z",
     "shell.execute_reply": "2021-11-27T06:48:01.979718Z",
     "shell.execute_reply.started": "2021-11-27T06:43:32.910822Z"
    },
    "id": "q6A9Q0xmI5VJ",
    "outputId": "448e8b96-5714-4b30-de9e-bff01ccad9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/49 [==============================] - 29s 555ms/step - loss: 0.7012 - accuracy: 0.5041\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 27s 552ms/step - loss: 0.6960 - accuracy: 0.4998\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 28s 565ms/step - loss: 0.6949 - accuracy: 0.4988\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 27s 548ms/step - loss: 0.6942 - accuracy: 0.5045\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 26s 538ms/step - loss: 0.6932 - accuracy: 0.5157\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 26s 536ms/step - loss: 0.6910 - accuracy: 0.5222\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 27s 548ms/step - loss: 0.6610 - accuracy: 0.5963\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 26s 523ms/step - loss: 0.5752 - accuracy: 0.6961\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 26s 536ms/step - loss: 0.6534 - accuracy: 0.6059\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 27s 549ms/step - loss: 0.5809 - accuracy: 0.6896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a31b9f6d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define batch size.\n",
    "batch_size = 512\n",
    "num_epochs = 10\n",
    "# Define the model and train it.\n",
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:48:01.982667Z",
     "iopub.status.busy": "2021-11-27T06:48:01.982401Z",
     "iopub.status.idle": "2021-11-27T06:48:42.984895Z",
     "shell.execute_reply": "2021-11-27T06:48:42.984083Z",
     "shell.execute_reply.started": "2021-11-27T06:48:01.982623Z"
    },
    "id": "YTXG__EmI5VM",
    "outputId": "e69660fc-aa66-4b2a-df71-5c4510bdbf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 22s 28ms/step - loss: 0.4976 - accuracy: 0.7670\n",
      "Test accuracy: 0.7670000195503235\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model using model.evaluate()\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1uSo8DgI5VN"
   },
   "source": [
    "# **LSTM**\n",
    "\n",
    "**Instead of using a RNN, now try using a LSTM model and compare both of them. Which of those performed better and why ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:48:42.986510Z",
     "iopub.status.busy": "2021-11-27T06:48:42.986258Z",
     "iopub.status.idle": "2021-11-27T06:48:44.612389Z",
     "shell.execute_reply": "2021-11-27T06:48:44.611613Z",
     "shell.execute_reply.started": "2021-11-27T06:48:42.986476Z"
    },
    "id": "Bk4rLYHwI5VP",
    "outputId": "4bf93d07-883a-4585-f90f-f07126a7d077"
   },
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "embedding_size=32\n",
    "model_lstm.add(Embedding(vocabulary_size, embedding_size, input_length=132, mask_zero=True))\n",
    "model_lstm.add(LSTM(128, dropout=0.1, return_sequences=True))#recurrent_dropout=0.1, \n",
    "model_lstm.add(LSTM(64, dropout=0.1, return_sequences=False))\n",
    "model_lstm.add(Dense(32, activation='relu'))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:48:44.614536Z",
     "iopub.status.busy": "2021-11-27T06:48:44.614297Z",
     "iopub.status.idle": "2021-11-27T06:48:44.630213Z",
     "shell.execute_reply": "2021-11-27T06:48:44.628834Z",
     "shell.execute_reply.started": "2021-11-27T06:48:44.614503Z"
    },
    "id": "mCnJ_Qvs4LN-",
    "outputId": "52c48289-6d04-4175-b1d1-bf09d311a226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 132, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 132, 128)          82432     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 293,953\n",
      "Trainable params: 293,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM model and compile and show it's summary\n",
    "model_lstm.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:48:44.631821Z",
     "iopub.status.busy": "2021-11-27T06:48:44.631528Z",
     "iopub.status.idle": "2021-11-27T06:55:10.362643Z",
     "shell.execute_reply": "2021-11-27T06:55:10.361978Z",
     "shell.execute_reply.started": "2021-11-27T06:48:44.631763Z"
    },
    "id": "pOoFeE2X4LLE",
    "outputId": "64f7b826-52d1-4dd1-dee4-50a0b564a3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/49 [==============================] - 49s 771ms/step - loss: 0.5708 - accuracy: 0.6876\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 38s 768ms/step - loss: 0.3285 - accuracy: 0.8638\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 38s 759ms/step - loss: 0.2627 - accuracy: 0.8964\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 37s 756ms/step - loss: 0.2429 - accuracy: 0.9054\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 37s 758ms/step - loss: 0.2287 - accuracy: 0.9125\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 37s 748ms/step - loss: 0.2200 - accuracy: 0.9158\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 37s 762ms/step - loss: 0.1971 - accuracy: 0.9280\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 38s 773ms/step - loss: 0.1833 - accuracy: 0.9346\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 38s 777ms/step - loss: 0.1685 - accuracy: 0.9407\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 37s 761ms/step - loss: 0.1532 - accuracy: 0.9489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a374f2810>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define batch size and number of epochs.\n",
    "batch_size = 512\n",
    "num_epochs = 10\n",
    "# Train the LSTM model.\n",
    "model_lstm.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T06:55:10.364332Z",
     "iopub.status.busy": "2021-11-27T06:55:10.364060Z",
     "iopub.status.idle": "2021-11-27T06:55:50.683243Z",
     "shell.execute_reply": "2021-11-27T06:55:50.682477Z",
     "shell.execute_reply.started": "2021-11-27T06:55:10.364297Z"
    },
    "id": "DSa01QFS4LI1",
    "outputId": "af296837-fc84-4621-d7c5-47503a6fdc0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 40s 49ms/step - loss: 0.4590 - accuracy: 0.8404\n",
      "Test accuracy for LSTM: 0.8404399752616882\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model using model.evaluate()\n",
    "\n",
    "score_lstm = model_lstm.evaluate(X_test, y_test, verbose = 1)\n",
    "print('Test accuracy for LSTM:', score_lstm[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "1. The training time `LSTM` model is more than as compared to the `SimpleRNN` model, with same number of recurrent units ($128$ and $64$) and Dense layers (i.e., $64$ and $1$). And it was apparent from the number of **trainable parameters** both model posses, that is, $293953$ for `LSTM` and $197185$ for `SimpleRNN`. Both are trained with same `batch_size=512`, `epochs=10` with same embedding (of $32$) and maximum length of the input for both the models (i.e. $132$).\n",
    "2. The `SimpleRNN` model gave an accuracy of $76.70\\%$, whereas for the `LSTM` model it was $84.04\\%$. Further, `LSTM` performed better than `SimpleRNN`, because simple RNN has an inherent issue of **vanishing gradients**, which is addressed in the LSTM. Plus, it has multiple 'gates' in its cell that decides on amount of previous activation matter to pass on to the next cell, which accounts for memorizing information for longer periods.\n",
    "3. Not only that, LSTMs also maintains a `cell state` along with the `hidden state` that's responsible for capturing long-term and overall meaning of the semantics which results in absolute increase of overall performance when compared to Simple RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBtRY9jmI5VQ"
   },
   "source": [
    "**Perform Error analysis and explain using few examples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Load $20$ samples from test data and see how each model performs on them.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T07:21:08.251478Z",
     "iopub.status.busy": "2021-11-27T07:21:08.250573Z",
     "iopub.status.idle": "2021-11-27T07:21:08.336638Z",
     "shell.execute_reply": "2021-11-27T07:21:08.335989Z",
     "shell.execute_reply.started": "2021-11-27T07:21:08.251434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word index dictionary (first 10 entries)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('fawn', 34701),\n",
       " ('tsukino', 52006),\n",
       " ('nunnery', 52007),\n",
       " ('sonja', 16816),\n",
       " ('vani', 63951),\n",
       " ('woods', 1408),\n",
       " ('spiders', 16115),\n",
       " ('hanging', 2345),\n",
       " ('woody', 2289),\n",
       " ('trawling', 52008)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's import first 10 entries from DIsctionary and we'll analyse performance of both of our models.\n",
    "# Dictionary that conatins word index as values and word as keys.\n",
    "from itertools import islice\n",
    "word_index = imdb.get_word_index()\n",
    "print(\"Word index dictionary (first 10 entries)\")\n",
    "(list(islice(word_index.items(), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:00:04.041336Z",
     "iopub.status.busy": "2021-11-27T08:00:04.040778Z",
     "iopub.status.idle": "2021-11-27T08:00:04.048205Z",
     "shell.execute_reply": "2021-11-27T08:00:04.047350Z",
     "shell.execute_reply.started": "2021-11-27T08:00:04.041299Z"
    }
   },
   "outputs": [],
   "source": [
    "def reviewInText(vector):\n",
    "    \"\"\"\n",
    "    Convert the review vector to text form.\n",
    "    \"\"\"\n",
    "    reverse_index = dict([(value,key) for (key,value) in imdb.get_word_index().items()])\n",
    "    review = \" \".join([reverse_index.get(i-3, \"!\") for i in vector])\n",
    "    return review\n",
    "\n",
    "# Set a sed and choose randomly 20 samples from Test data.\n",
    "np.random.seed(25)\n",
    "random_index = np.random.choice(25000,20,replace=False)\n",
    "# Store the random samples taken.\n",
    "random_test_samples = X_test[random_index, :]\n",
    "random_test_sample_labels = y_test[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:01:22.991655Z",
     "iopub.status.busy": "2021-11-27T08:01:22.991378Z",
     "iopub.status.idle": "2021-11-27T08:01:24.494536Z",
     "shell.execute_reply": "2021-11-27T08:01:24.493825Z",
     "shell.execute_reply.started": "2021-11-27T08:01:22.991623Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected reviews and their actual labels.\n",
      "\n",
      "\n",
      "1. ! have somehow ! and have become the focus of their lives br br all of them somehow come to terms with and their past demons all of them except the first one who realizes the only way he can move on through life is getting flat ! again during this flat line ! he sees himself getting flat ! the first time and also sees the boy he killed trying to kill him this time round the boy kills him this time for a few minutes and in doing so has ! revenge for a few minutes in the movie one is left wondering if he gets to come back thankfully because most of us like happy endings the boy him of his past and he comes back to life again\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "2. costumes cinematography and music are gorgeous the acting writing and directing are extremely strong and filled with realism class and originality i loved the film and the novel section iii in the film is much different in the film than in the novel because section iii in the novel is great written down but isn't screen material i will be brave and say that i love the films interpretation of it much more br br this breathtaking historical ! ! drama comedy ! and romance to ! perfection in a way that is both deeply moving and ! ! for every mature and open minded adult who has ever felt the ! ! and power of falling in love and living life to it's ! a revolutionary production an absolute must see\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : POSITIVE\n",
      "\n",
      "\n",
      "3. ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! an excellent debut movie for the the director of batman begins comes the following a movie about a man who follows other people for inspiration of characters in stories he writes one man he follows he decides to go further and the man turns out to be more than he ! for br br using a cast of non actors and his uncle writing directing producing and otherwise completely making this movie entirely on his own with almost no budget and produced ! this movie is much more than you'd expect br br for anyone who likes ! and complex twists turns ! and ! around with time this is definitely a movie for you\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : POSITIVE\n",
      "\n",
      "\n",
      "4. because it doesn't match ! must believe their case fails miserably on facts and ! else why resort to ! ! and blatant one pathetic br br don't be a ! take two seconds and cast a ! eye before falling for yet more ! of the ! ! from it takes a village types with a political ! that's probably even to the left of your own ! moore rather his ! ! have really opened the ! with this kind of one ! political trash passed off as a ! documentary but apparently they understand the ! of an ever ! public if it's on a movie screen it must be true br br god gave you a brain act like you know what you're supposed to do with it\n",
      "\n",
      "Actual (Ground Truth) Label : NEGATIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "5. ! ! ! ! ! ! ! ! ! ! ! ! i just have watched icon on dvd and despite being a great book the movie is a weak from it those responsible for the writing should be ! to ! why they ! the great story with all kind of c film which are totally irrelevant to the story is totally beyond me br br yet the filmmakers and cast do there best to make something out of it but at the end the film was not satisfying at all br br can someone please make a decent movie out of this to show how it is done i'm sure that the ! will ! for such a masterpiece novel turned into a book not into a cheap c movie\n",
      "\n",
      "Actual (Ground Truth) Label : NEGATIVE\n",
      "RNN predictions : NEGATIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "6. the rest of the movie as i ! the plot never drew me in i just didn't care about what was going on and the notion that the boy is so quickly attracted to the criminal lifestyle doesn't ring true as for the other actors mark ! is almost as bad as ! and the usually ! franco ! isn't a whole lot better three name actors and not a good performance between them to make matters worse i believe the director filmed many of the night scenes with nothing more than the ! from his watch to light the shots i couldn't tell what was going on characters i hate a plot i don't care about and a production values that failed  little wonder i've given ! a 3 10\n",
      "\n",
      "Actual (Ground Truth) Label : NEGATIVE\n",
      "RNN predictions : NEGATIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "7. doing it based on his beliefs is doing it strictly for the money the soviet ! is ! played by david ! ! and ! have a real quirky chemistry and it's a kind of funny set of ! between them but make no mistake this film is anything but that it is a serious character study about ! ! paranoia and ! br br again the leads make this film ! delivers a brilliantly understated performance as chris a rather smart young man who had so much potential ! as usual does a tremendous characterization as a pathetic loser who acts before he thinks and most of the time doesn't think at all the ending of this fact based film is very ! on several levels a truly powerful character study\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : POSITIVE\n",
      "\n",
      "\n",
      "8. right there but unfortunately it all gets rather ! and becomes so complicated that the viewer like myself will most likely become frustrated characters appear with little introduction and you're not really sure who they are or why sarah knows them or is hanging out with them all of this has something to do with this woman who tried to ! a young boy years ago and her reason for that was that it's all part of the design in reality it's all part of the very ! script and when the film is over you'll find yourself feeling that you've lost about an hour and a half of your life that you want back for more ! uses of your time like ! the bathroom for instance 4 out of 10\n",
      "\n",
      "Actual (Ground Truth) Label : NEGATIVE\n",
      "RNN predictions : NEGATIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "9. table is a big movie star none other than lloyd hamilton there's a very well made double exposure shot the join is nearly invisible when lloyd hamilton as himself ! lloyd hamilton as the country boy br br sadly ! ! period of creativity was very brief he began his film career in crude slapstick films as one half of a double act ham and ! opposite ! ! and had a brief and ! period of ! in shorts during the late silent period sound movies were not kind to hamilton and he was quickly ! down the cast list in some crude early ! then he died young fortunately 'the ! is quite funny and a splendid introduction to this unique ! style i'll rate it 7 out of 10\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : POSITIVE\n",
      "\n",
      "\n",
      "10. with hilarious consequences br br ! g is a great british movie that brings the ! talented ! of writing along with dan executive production and acting of ! ! ! charles dance and michael as the p m play their parts with great ! among the gags and ! that is ! g br br ironically seeing the ! playing their parts in a world that really is real and who are ! ! keep it real from their own little world that is the west is true comic ! br br directed by mark his first full length feature film since directing television work such as ! shooting stars the fast show and the ! of ! and ! to name a few br br very real and very funny\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : POSITIVE\n",
      "\n",
      "\n",
      "11. times the possibility to get away from your enemy and u don't do it its getting boring there are in the movie witch gives u the impression that they are forgotten e g a in front of a security ! they are asking for help and a somebody sees it and the police than there is a cut and nothing the killer gets a shot in his head and 50 ! later he is ! like nothing happened no its no zombie movie and finally the final the big end which we were promised ! lets say take a little guy who always wanted to give the world one of the best endings in history so badly that everything goes wrong im not going to vote 1 because the actress is beautiful\n",
      "\n",
      "Actual (Ground Truth) Label : NEGATIVE\n",
      "RNN predictions : NEGATIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "12. make an ! film ! intentions are fine but if i wanted 2 hours of ! ! i would visit my ! sunday school father struggle with his faith as presented in his younger days is a potentially interesting subject but an ! movie needs more the ! ! presentation along with ridiculous special effects makes for a strange production who is this movie for i didn't bother seeing the ! version but at least they apparently tried to deliver some sort of ! thrills br br the ! series has been quite strange the first film was excellent but every sequel has been ! and pointless why do they keep making them i suppose ! made it so that he could get a lot of money but why should we go\n",
      "\n",
      "Actual (Ground Truth) Label : NEGATIVE\n",
      "RNN predictions : NEGATIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "13. film is a great media to do that well all great actors together hence nothing to say about acting or directing but the film gave us a great message through out it has nicely ! the ! of human minds with that of the patient we all believe that what we believe is true with our own point of view and we want to solve all the problem ! hence from the professor to the ! ! all tried their own ways so when was ! with her wife he says that ! is looking for a thing which she will never and the wife ! ! not we all ' so that was a great comment which after the film left me with a great question ! we all sick '\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : POSITIVE\n",
      "\n",
      "\n",
      "14. ! kind of me out as a ! but it's funny seeing the parents trying to get their kids to eat ! tongue and any episode that mentions godzilla versus the ! monster twice can't be all bad i like bad day even more although it's ! to see going through a rough day she does imagine herself getting revenge on her friend ! uncle a pre factor ! hope who always ! her the perfect day is also good br br ! plays sister i swear i've seen her on something else but imdb doesn't list anything besides this show unfortunately this series is not on dvd why is every crappy show made these days on dvd except something i'd actually like to buy an ! if there ever was one\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : NEGATIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "15. ! to blues ! r l ! no doubt everything works about this movie let's face it including the music soundtrack which features ! scott bobby rush son house and most importantly jackson himself whose fantastic version of i am listening to as i ! this review there's also a really beautiful and moving version of this little light of mine featured in the film ! heart ! ! and soft by ! br br ! jackson has said in recent interviews that he believes his performance in this movie is the best of his career thus far i could not agree with him more this is work that he can be ! proud of along with everyone else involved in this ! ! wise and deeply ! mother of a project\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : POSITIVE\n",
      "\n",
      "\n",
      "16. ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! this is a low grade cold war propaganda film ! with a it may have some long term ! as a ! of 1950s us thinking but there is little else to ! in the ! storyline wooden acting and ! style there are some interesting photos of long gone ! but that was not enough for even this ! ! to leave it on the screen for the full length\n",
      "\n",
      "Actual (Ground Truth) Label : NEGATIVE\n",
      "RNN predictions : NEGATIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "17. etc etc you hear terms like fighter wizard hit point level character ! hand ! evil br br what ! fancy me is that it let you do anything u want to not ! by ! ! ! dr provide the same element you wont know what happen next and it probably just make you laugh to dead the movie goes both real life as well as in the d d world you will hear the ! cast the ! when the character in game take action which make you feel you really in the game br br i don't want to spoil anything but in short ! dr is a must watch movie for ! lovers for people never play ! game i'm sure you still get many fun from it\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : POSITIVE\n",
      "\n",
      "\n",
      "18. and going to the other because it looked like a fun movie with action romance thrills ! and exotic locations they had all that but so do a lot of movies with a ! of story br br all i can say is why why why why did they not just make it a straight narrative instead of some sappy flashback story br br here is all the movies from what i've seen the film was ! from of course ! jones and ! the stone but also true lies proof of life that old 80s tom ! movie ! woody allen and hero from the use of digital extras br br ! the only scene in the movie that was cool is when the central character finds her room blown up\n",
      "\n",
      "Actual (Ground Truth) Label : NEGATIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n",
      "19. ! ! ! ! ! ! ! ! ! ! ! ! is a movie that is ! of the american system at it's worst the ! system was initially set up as a ! stone for those families who needed that extra hand to get back on their feet the movie showed an accurate portrayal of how the ! system breaks down the family unit in other words if the father or any male figure is in the lives of the women and children their financial support from the system would be ! if not ! the struggles of the poor can be seen throughout the world i would like to see a ! of this movie back in the ! for all to rent or buy for their library collection\n",
      "\n",
      "Actual (Ground Truth) Label : POSITIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : POSITIVE\n",
      "\n",
      "\n",
      "20. and back faster than a ! bullet and for what purpose conflict conflict conflict at the drop of a hat ! the california girl and her boyfriend mom and everybody including the poor lady at the airport check in counter ! ! father who is the ! most ! man alive and his wife and ! son all in constant conflict i really wanted to enjoy a ! story but the only thing that made me smile was when all the hate and fighting were over there were too many ! or illogical events many of which don't add to the story my wife and i kept looking at each other and asking ourselves how such a good cast and what should be a great story could be ! up so badly\n",
      "\n",
      "Actual (Ground Truth) Label : NEGATIVE\n",
      "RNN predictions : POSITIVE\n",
      "LSTM predictions : NEGATIVE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on Test data set.\n",
    "# Predict with RNN.\n",
    "RNN_labels = model.predict(random_test_samples)\n",
    "RNN_labels[RNN_labels>=0.5] = 1\n",
    "RNN_labels[RNN_labels<0.5] = 0\n",
    "# Predict with LSTM.\n",
    "LSTM_labels = model_lstm.predict(random_test_samples)\n",
    "LSTM_labels[LSTM_labels>=0.5] = 1\n",
    "LSTM_labels[LSTM_labels<0.5] = 0\n",
    "\n",
    "# Show the actual labels (ground truth values.)\n",
    "print(\"Randomly selected reviews and their actual labels.\\n\\n\")\n",
    "\n",
    "for k, review in enumerate(random_test_samples):\n",
    "    print(f\"{k+1}.\", end = \" \")\n",
    "    print(reviewInText(review))\n",
    "    print()\n",
    "    print(\"Actual (Ground Truth) Label :\", end = \" \")\n",
    "    if random_test_sample_labels[k] == 1:\n",
    "        print(\"POSITIVE\")\n",
    "    else:\n",
    "        print(\"NEGATIVE\")\n",
    "    print(\"RNN predictions :\", end = \" \")\n",
    "    if RNN_labels[k] ==1:\n",
    "        print(\"POSITIVE\")\n",
    "    else:\n",
    "        print(\"NEGATIVE\")\n",
    "    print(\"LSTM predictions :\", end = \" \")\n",
    "    if LSTM_labels[k] ==1:\n",
    "        print(\"POSITIVE\\n\\n\")\n",
    "    else:\n",
    "        print(\"NEGATIVE\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Analysis: Reviewed in Bottom-Up fashion**\n",
    "\n",
    "1. $20$--> Since `RNN` mostly focuses on a local small group of words, like \"made me smile\", \"good cast\", \"great story\", it made it classified as \"POSITIVE\", while LSTM is able to remember the past semantics as well as able to draw out the whole meaning. Plus, its encounter the sarcasm \"up so badly\" which made it classified as \"NEGATIVE\" sentiment.\n",
    "\n",
    "2. $18$--> Again this review consists of short group of positive words that made RNN think as \"POSITIVE\" sentiment while it wasn't\n",
    "\n",
    "3. $14$--> Even if this was a positive review, both the models marked it as \"NEGATIVE\" sentiment due to over-usage of negative words from start to last, like \"can't be all bad\", \"rough day\", \"revenge\", \"doesn't list anything\", \"unfortunately\", \"not on dvd\", etc.\n",
    "\n",
    "4. $4$--> We can clearly see even though the whole review feels as \"NEGATIVE\", but the last 1-2 sentences doesn't conatins any negative semantics which results in \"POSITIVE\" flagging of the review.\n",
    "\n",
    "5. $5$--> As we go through the whole there are negative words in each statement except the last one, which is purely in positive sense. So overall the sentence displays some meaning that a human can sense it as \"POSITIVE\", but since `LSTM` has this behaviour to remember all the meanings of individual words and accumulate their sentiments over time, it flags it as \"NEGATIVE\" while for the `RNN` it was \"POSITIVE\" due to the last statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough-Work"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-26T17:46:25.816294Z",
     "iopub.status.busy": "2021-11-26T17:46:25.815989Z",
     "iopub.status.idle": "2021-11-26T17:46:25.890058Z",
     "shell.execute_reply": "2021-11-26T17:46:25.889078Z",
     "shell.execute_reply.started": "2021-11-26T17:46:25.816215Z"
    }
   },
   "source": [
    "# Randomly choose 10 samples.\n",
    "from sklearn.utils.random import resample\n",
    "#data_test = np.concatenate((X_test, y_test.reshape(-1, 1)), axis = 1)\n",
    "sampled_X, sampled_y = resample(X_test, y_test, n_samples=10, replace=False, stratify=y_test, random_state=23)\n",
    "\n",
    "# Predict these 10 samples with their labels.\n",
    "# SimpleRNN\n",
    "pred_rnn = model.predict(sampled_X)\n",
    "# LSTM\n",
    "pred_lst = model_lstm.predict(sampled_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
